{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33cee624-b9bf-4a9f-b82e-4938d3a429eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Input, MaxPooling2D, BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import Model, regularizers\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from time import time\n",
    "import csv\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "from helper import load_and_preprocess_image, generator_from_csv\n",
    "\n",
    "# Set the seeds for reproducibility\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "seed_value = 1234578790\n",
    "seed(seed_value)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f0535a5-3723-4744-8519-ee6e44fd80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV paths\n",
    "TRAIN_CSV = 'annotations_train.csv'\n",
    "VAL_CSV   = 'annotations_val.csv'\n",
    "TEST_CSV  = 'annotations_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e188b2c9-1d28-4f05-871c-27a529708573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH  = 256\n",
    "CHANNELS   = 3\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89d25188-be47-4343-af54-98188d449115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators for train, val, test sets\n",
    "train_gen = generator_from_csv(TRAIN_CSV, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_gen   = generator_from_csv(VAL_CSV,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_gen  = generator_from_csv(TEST_CSV,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Let's guess how many lines are in each CSV\n",
    "train_lines = sum(1 for _ in open(TRAIN_CSV)) - 1  # minus header\n",
    "val_lines   = sum(1 for _ in open(VAL_CSV))   - 1\n",
    "test_lines  = sum(1 for _ in open(TEST_CSV))  - 1\n",
    "\n",
    "# Steps per epoch\n",
    "steps_per_epoch      = train_lines // BATCH_SIZE\n",
    "validation_steps     = val_lines   // BATCH_SIZE\n",
    "test_steps           = test_lines  // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d474ed-1369-4c98-9cff-05c4ff2af252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks using mse\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=1e-6, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10,\n",
    "                           restore_best_weights=True, verbose=1)\n",
    "checkpoint = ModelCheckpoint('unet_best_model.h5', monitor='val_loss',\n",
    "                             save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1208cc74-5b2e-44a3-9a76-9b0e41202055",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf4f899-9c9d-4cb1-b456-a6706fcc8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape=(256, 256, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = layers.concatenate([u4, c2])\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4)\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "    \n",
    "    u5 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = layers.concatenate([u5, c1])\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(c5)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e2253-3cc7-4d96-b547-f8088cd0995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_dncnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy', 'mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6d77f-d544-449b-8f39-681b0ab6eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902855b0-76fb-4b31-9c4e-56a05c1ad813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5e6a8-ba52-448a-a582-82dd963112c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    h = history.history\n",
    "    epochs = range(len(h['loss']))\n",
    "\n",
    "    plt.subplot(121), plt.plot(epochs, h['loss'], '.-', epochs, h['val_loss'], '.-')\n",
    "    plt.grid(True), plt.xlabel('epochs'), plt.ylabel('loss')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.subplot(122), plt.plot(epochs, h['accuracy'], '.-',\n",
    "                               epochs, h['val_accuracy'], '.-')\n",
    "    plt.grid(True), plt.xlabel('epochs'), plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "        \n",
    "    print('Train Acc     ', h['accuracy'][-1])\n",
    "    print('Validation Acc', h['val_accuracy'][-1])\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bc28162-3a86-4039-9305-3dcf09bd1e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model PSNR: 36.702814020810976\n",
      "Gaussian PSNR: 32.64933119450204\n"
     ]
    }
   ],
   "source": [
    "def mse(img1, img2):\n",
    "    return np.mean((img1 - img2)**2)\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    # Assumes images in [0..1], so max_val = 1.0\n",
    "    mse_val = mse(img1, img2)\n",
    "    if mse_val == 0:\n",
    "        return 100  # max PSNR if identical\n",
    "    return 10 * np.log10(1.0 / mse_val)\n",
    "\n",
    "# Compare model output vs ground truth\n",
    "model_psnr = psnr(predicts[idx], original_batch[idx])\n",
    "print(\"Model PSNR:\", model_psnr)\n",
    "\n",
    "# Compare Gaussian vs ground truth\n",
    "gaussian_psnr = psnr(gaussian_img, original_batch[idx])\n",
    "print(\"Gaussian PSNR:\", gaussian_psnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdf1edd4-125f-4877-bfa4-f3f3f0e31c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 45s 227ms/step - loss: 0.0233 - accuracy: 0.8800 - mae: 0.0233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.023345565423369408, 0.8799682855606079, 0.023345565423369408]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_gen, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b0dac-bb14-4a83-8493-d9a52cb31ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6857126-d9ac-46dc-8251-10e7eafeced5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
